{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9176789-334e-4d1b-bd6d-4c0f9df804b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import random\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cec54a-f043-4d35-8eaa-90dec9ca7771",
   "metadata": {},
   "source": [
    "# Data preprocessing for our models\n",
    "\n",
    "##### We still have some data preprocessing to do for our ML models. Here, we are focusing on datatypes and feature scaling to ensure the model can interpret the data much better.\n",
    "\n",
    "\n",
    "##### I have opted to make 0/1 data columns (where 1= true) boolean for memory efficiency and interpretability by the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ae989ad-8bab-4135-a673-18edc52bccf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>height(cm)</th>\n",
       "      <th>weight(kg)</th>\n",
       "      <th>BMI(kg/m2)</th>\n",
       "      <th>SBP(mmHg)</th>\n",
       "      <th>DBP(mmHg)</th>\n",
       "      <th>FPG(mmol/L)</th>\n",
       "      <th>Cholesterol(mmol/L)</th>\n",
       "      <th>...</th>\n",
       "      <th>LDL(mmol/L)</th>\n",
       "      <th>ALT(U/L)</th>\n",
       "      <th>AST(U/L)</th>\n",
       "      <th>BUN(mmol/L)</th>\n",
       "      <th>CCR(umol/L)</th>\n",
       "      <th>FPG_Final</th>\n",
       "      <th>Censor_Diabetes_Diagnosed</th>\n",
       "      <th>Smoking_status</th>\n",
       "      <th>Drinking_status</th>\n",
       "      <th>Family_history_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>166.4</td>\n",
       "      <td>53.5</td>\n",
       "      <td>19.3</td>\n",
       "      <td>96.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>4.99</td>\n",
       "      <td>5.13</td>\n",
       "      <td>...</td>\n",
       "      <td>2.768231</td>\n",
       "      <td>10.0</td>\n",
       "      <td>24.084889</td>\n",
       "      <td>3.080000</td>\n",
       "      <td>50.3</td>\n",
       "      <td>4.97</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>165.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>23.1</td>\n",
       "      <td>136.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>5.70</td>\n",
       "      <td>4.50</td>\n",
       "      <td>...</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>24.084889</td>\n",
       "      <td>5.760000</td>\n",
       "      <td>62.6</td>\n",
       "      <td>5.50</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>161.5</td>\n",
       "      <td>58.5</td>\n",
       "      <td>22.4</td>\n",
       "      <td>104.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>5.78</td>\n",
       "      <td>4.48</td>\n",
       "      <td>...</td>\n",
       "      <td>2.768231</td>\n",
       "      <td>23.6</td>\n",
       "      <td>24.084889</td>\n",
       "      <td>6.820000</td>\n",
       "      <td>96.5</td>\n",
       "      <td>5.10</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>157.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>20.3</td>\n",
       "      <td>102.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>5.70</td>\n",
       "      <td>4.05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.768231</td>\n",
       "      <td>13.2</td>\n",
       "      <td>24.084889</td>\n",
       "      <td>4.657683</td>\n",
       "      <td>51.2</td>\n",
       "      <td>4.85</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>156.0</td>\n",
       "      <td>60.5</td>\n",
       "      <td>24.9</td>\n",
       "      <td>133.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>5.80</td>\n",
       "      <td>4.67</td>\n",
       "      <td>...</td>\n",
       "      <td>2.320000</td>\n",
       "      <td>23.8</td>\n",
       "      <td>28.900000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>89.8</td>\n",
       "      <td>6.31</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Age  Gender  height(cm)  weight(kg)  BMI(kg/m2)  SBP(mmHg)  DBP(mmHg)  \\\n",
       "0   1   43       2       166.4        53.5        19.3       96.0       57.0   \n",
       "1  11   59       1       165.0        63.0        23.1      136.0       73.0   \n",
       "2  34   31       1       161.5        58.5        22.4      104.0       74.0   \n",
       "3  53   25       2       157.0        50.0        20.3      102.0       60.0   \n",
       "4  59   66       1       156.0        60.5        24.9      133.0       78.0   \n",
       "\n",
       "   FPG(mmol/L)  Cholesterol(mmol/L)  ...  LDL(mmol/L)  ALT(U/L)   AST(U/L)  \\\n",
       "0         4.99                 5.13  ...     2.768231      10.0  24.084889   \n",
       "1         5.70                 4.50  ...     2.800000      15.0  24.084889   \n",
       "2         5.78                 4.48  ...     2.768231      23.6  24.084889   \n",
       "3         5.70                 4.05  ...     2.768231      13.2  24.084889   \n",
       "4         5.80                 4.67  ...     2.320000      23.8  28.900000   \n",
       "\n",
       "   BUN(mmol/L)  CCR(umol/L)  FPG_Final  Censor_Diabetes_Diagnosed  \\\n",
       "0     3.080000         50.3       4.97                          0   \n",
       "1     5.760000         62.6       5.50                          0   \n",
       "2     6.820000         96.5       5.10                          0   \n",
       "3     4.657683         51.2       4.85                          0   \n",
       "4     6.600000         89.8       6.31                          0   \n",
       "\n",
       "   Smoking_status  Drinking_status   Family_history_diabetes  \n",
       "0             3.0              3.0                         1  \n",
       "1             3.0              3.0                         0  \n",
       "2             3.0              3.0                         0  \n",
       "3             3.0              3.0                         0  \n",
       "4             1.0              3.0                         0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_df = pd.read_csv('Final_diabetes.csv')\n",
    "Final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6051d560-3e10-4ec8-ae7a-dfc8aa414114",
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_df['Gender'] = Final_df['Gender'].map({1: True, 2: False})\n",
    "Final_df['Censor_Diabetes_Diagnosed'] = Final_df['Censor_Diabetes_Diagnosed'].astype(bool)\n",
    "Final_df[' Family_history_diabetes'] = Final_df[' Family_history_diabetes'].astype(bool)\n",
    "Final_df['Smoking_status'] = Final_df['Smoking_status'].astype('int64')\n",
    "Final_df['Drinking_status'] = Final_df['Drinking_status'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4c729bd-082f-412b-a681-37eb084f3cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                             int64\n",
       "Age                            int64\n",
       "Gender                          bool\n",
       "height(cm)                   float64\n",
       "weight(kg)                   float64\n",
       "BMI(kg/m2)                   float64\n",
       "SBP(mmHg)                    float64\n",
       "DBP(mmHg)                    float64\n",
       "FPG(mmol/L)                  float64\n",
       "Cholesterol(mmol/L)          float64\n",
       "Triglyceride(mmol/L)         float64\n",
       "HDL(mmol/L)                  float64\n",
       "LDL(mmol/L)                  float64\n",
       "ALT(U/L)                     float64\n",
       "AST(U/L)                     float64\n",
       "BUN(mmol/L)                  float64\n",
       "CCR(umol/L)                  float64\n",
       "FPG_Final                    float64\n",
       "Censor_Diabetes_Diagnosed       bool\n",
       "Smoking_status                 int64\n",
       "Drinking_status                int64\n",
       " Family_history_diabetes        bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cca944-67f8-46ea-b204-9d8db5c17324",
   "metadata": {},
   "source": [
    "##### We do not need to one-hot encode anything here, since all data types are bool, int or float. If you recall, our 2 columns 'smoking_status' and 'drinking_status' have already been formatted via label encoding by the creator of the dataset- since there is an order from 1-3 denoting smoking and drinking intensity.This label encoding is also highly suitable for our tree-based models we are planning to use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01e70f1b-f536-4093-8cfc-c8e9eaddc04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets strip the whitespace with our family_history_diabetes column! \n",
    "Final_df.columns = Final_df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0da1aae-c698-40a4-aa1e-bfe372702b89",
   "metadata": {},
   "source": [
    "# Now lets split the data into training, test and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff83819e-078c-4efc-b4ae-1135ae679201",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= Final_df.drop(['Censor_Diabetes_Diagnosed','id'], axis=1)\n",
    "y= Final_df['Censor_Diabetes_Diagnosed']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85afb647-71d6-405c-ba5f-c131549aa4d4",
   "metadata": {},
   "source": [
    "##### We are dropping our 'target' value and the 'id' column as Censor_Diabetes_Diagnosed is our target value and the 'id' does not function as a predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7843b483-1e35-4b8d-b2b9-6db23e26e5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_rem, y_train, y_rem = train_test_split(x, y, train_size=0.6, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc027086-96f4-4430-9e2d-7ce92c935e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: x_train: (36138, 20) y_train: (36138,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set shape: x_train:\", x_train.shape, \"y_train:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31656e94-e23b-443b-81d7-8ba310236fd7",
   "metadata": {},
   "source": [
    "##### Now splitting the remaining data into test and validation datasets.\n",
    "##### Validation to tune and validate the model parameters. I am using a seperate dataset as the model may be overexposed to the training data when hyperparamater tuning and thus would benefit from a seperate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "666c06f8-6671-40d8-a182-295fa2141b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, x_test, y_val, y_test = train_test_split(x_rem, y_rem, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0c67c92-9393-4215-b664-ecc5301fc534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set shape: x_val: (12046, 20) y_val: (12046,)\n",
      "Testing set shape: x_test: (12046, 20) y_test: (12046,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation set shape: x_val:\", x_val.shape, \"y_val:\", y_val.shape)\n",
    "print(\"Testing set shape: x_test:\", x_test.shape, \"y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90328f7-1229-4c78-b2ba-2df8010632e8",
   "metadata": {},
   "source": [
    "#### Scaling the numerical data \n",
    "\n",
    "We have a wide range of numerical data, and whilst the medical data from blood test values may be closely linked, other values may not be. We need to ensure all features included all contribute equally to the model, which should improve their performance. We can see below there are features with much larger ranges than others e.g., smoking status is from 1-3 but we have height(cm) in a larger range. Scaling this data will help out distance-based algorithm we hope to employ (Support Vector Machines (SVM). Whilst scaling data is unecessary for tree-based models, since we are also employing an SVM, we need to scale the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf49b0b0-75d4-4ce5-8cfe-765bf80e255c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>height(cm)</th>\n",
       "      <th>weight(kg)</th>\n",
       "      <th>BMI(kg/m2)</th>\n",
       "      <th>SBP(mmHg)</th>\n",
       "      <th>DBP(mmHg)</th>\n",
       "      <th>FPG(mmol/L)</th>\n",
       "      <th>Cholesterol(mmol/L)</th>\n",
       "      <th>Triglyceride(mmol/L)</th>\n",
       "      <th>HDL(mmol/L)</th>\n",
       "      <th>LDL(mmol/L)</th>\n",
       "      <th>ALT(U/L)</th>\n",
       "      <th>AST(U/L)</th>\n",
       "      <th>BUN(mmol/L)</th>\n",
       "      <th>CCR(umol/L)</th>\n",
       "      <th>FPG_Final</th>\n",
       "      <th>Smoking_status</th>\n",
       "      <th>Drinking_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>166.4</td>\n",
       "      <td>53.5</td>\n",
       "      <td>19.3</td>\n",
       "      <td>96.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>4.99</td>\n",
       "      <td>5.13</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.372051</td>\n",
       "      <td>2.768231</td>\n",
       "      <td>10.0</td>\n",
       "      <td>24.084889</td>\n",
       "      <td>3.080000</td>\n",
       "      <td>50.3</td>\n",
       "      <td>4.97</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59</td>\n",
       "      <td>165.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>23.1</td>\n",
       "      <td>136.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>5.70</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.530000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>24.084889</td>\n",
       "      <td>5.760000</td>\n",
       "      <td>62.6</td>\n",
       "      <td>5.50</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>161.5</td>\n",
       "      <td>58.5</td>\n",
       "      <td>22.4</td>\n",
       "      <td>104.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>5.78</td>\n",
       "      <td>4.48</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.372051</td>\n",
       "      <td>2.768231</td>\n",
       "      <td>23.6</td>\n",
       "      <td>24.084889</td>\n",
       "      <td>6.820000</td>\n",
       "      <td>96.5</td>\n",
       "      <td>5.10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>157.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>20.3</td>\n",
       "      <td>102.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>5.70</td>\n",
       "      <td>4.05</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.372051</td>\n",
       "      <td>2.768231</td>\n",
       "      <td>13.2</td>\n",
       "      <td>24.084889</td>\n",
       "      <td>4.657683</td>\n",
       "      <td>51.2</td>\n",
       "      <td>4.85</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66</td>\n",
       "      <td>156.0</td>\n",
       "      <td>60.5</td>\n",
       "      <td>24.9</td>\n",
       "      <td>133.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>5.80</td>\n",
       "      <td>4.67</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.372051</td>\n",
       "      <td>2.320000</td>\n",
       "      <td>23.8</td>\n",
       "      <td>28.900000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>89.8</td>\n",
       "      <td>6.31</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  height(cm)  weight(kg)  BMI(kg/m2)  SBP(mmHg)  DBP(mmHg)  FPG(mmol/L)  \\\n",
       "0   43       166.4        53.5        19.3       96.0       57.0         4.99   \n",
       "1   59       165.0        63.0        23.1      136.0       73.0         5.70   \n",
       "2   31       161.5        58.5        22.4      104.0       74.0         5.78   \n",
       "3   25       157.0        50.0        20.3      102.0       60.0         5.70   \n",
       "4   66       156.0        60.5        24.9      133.0       78.0         5.80   \n",
       "\n",
       "   Cholesterol(mmol/L)  Triglyceride(mmol/L)  HDL(mmol/L)  LDL(mmol/L)  \\\n",
       "0                 5.13                  0.78     1.372051     2.768231   \n",
       "1                 4.50                  0.75     1.530000     2.800000   \n",
       "2                 4.48                  0.78     1.372051     2.768231   \n",
       "3                 4.05                  0.43     1.372051     2.768231   \n",
       "4                 4.67                  1.22     1.372051     2.320000   \n",
       "\n",
       "   ALT(U/L)   AST(U/L)  BUN(mmol/L)  CCR(umol/L)  FPG_Final  Smoking_status  \\\n",
       "0      10.0  24.084889     3.080000         50.3       4.97               3   \n",
       "1      15.0  24.084889     5.760000         62.6       5.50               3   \n",
       "2      23.6  24.084889     6.820000         96.5       5.10               3   \n",
       "3      13.2  24.084889     4.657683         51.2       4.85               3   \n",
       "4      23.8  28.900000     6.600000         89.8       6.31               1   \n",
       "\n",
       "   Drinking_status  \n",
       "0                3  \n",
       "1                3  \n",
       "2                3  \n",
       "3                3  \n",
       "4                3  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_cols = Final_df.select_dtypes(include=['float64', 'int64']).drop(columns=['id'], errors='ignore').columns\n",
    "Final_df[numerical_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b444d9f-abe1-4f01-b590-348986825434",
   "metadata": {},
   "source": [
    "##### We need to exclude the smoking and drinking status from the scaler as these are ordinal variables. Scaling these will lead to potential misinterpretation by our models.\n",
    "\n",
    "##### We have decided to use a Robust scaler from scikit-learn as there is alot of outliers as seen in our data preprocessing (see box plots)- thus we should aim to minimise this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3370d0a-e3d5-4ba5-88a9-8879874e73e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = numerical_cols.drop(['Smoking_status', 'Drinking_status']) # Dropping columns: The code removes the columns 'satisfaction_score' and 'number_of_referrals' from the numerical_cols list.\n",
    "\n",
    "scaler = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3935172-c920-447b-b818-0d948178b814",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[numerical_cols] = scaler.fit_transform(x_train[numerical_cols]) # Scaling the 3 datasets we have:\n",
    "x_test[numerical_cols] = scaler.fit_transform(x_test[numerical_cols])\n",
    "x_val[numerical_cols]= scaler.fit_transform(x_val[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59294f71-be5b-4376-b317-e6adce15c89c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Censor_Diabetes_Diagnosed\n",
       "False    35405\n",
       "True       733\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()\n",
    "# defining how wide a scope of diabetes doagnosis data we have... seem to have very little for true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c942723-4934-4cbe-a7a4-b1f35a6cc1cf",
   "metadata": {},
   "source": [
    "# Now that the data is ready for modelling, we will use 2 models: A SVM and a Tree-based model: Random Forest\n",
    "\n",
    "Why are we using these two? \n",
    "For medical diagnosis prediction, it is often never just one feature that only links to the disease- thus we should utilise all the features available to help build a better image of the predictability of type 2 diabetes- These 2 models are great at looking itno all features e..g, highly dimensional data. Furthermore given the numerous outliers in the dataset, we must use tree-based models and SVM to help reduce extreme values. Though, the drawbacks here are there is a higher chance of overfitting- these will have to be mitigated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797f5f4c-b221-4ff4-ab25-a3cb72eaf28d",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee27f8a-3563-491a-9bc8-65822d61beac",
   "metadata": {},
   "source": [
    "#### Why are we beginning with a RANDOM FOREST model?:\n",
    "\n",
    "The motivation to experiment with Random Forest lies in its ability to reduce overfitting and increase predictive performance by averaging the results of many decision trees. This ensemble method enhances stability and accuracy, making it less sensitive to the variations and noise in the dataset.\n",
    "\n",
    " The complexity of assessing multiple trees can make it less interpretable compared to a single decision tree, but its strengths in handling complex, high-dimensional data and reducing overfitting make it a powerful tool for predicting diabetes within our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2cee9cb5-5e2d-47ca-9be2-d2c81d153455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=3, min_samples_split=5, n_estimators=25,\n",
       "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(max_depth=3, min_samples_split=5, n_estimators=25,\n",
       "                       random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=3, min_samples_split=5, n_estimators=25,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=25, max_depth= 3, min_samples_split= 5, random_state=42)\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed70b666-a434-4ff4-8537-957a898e6cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "y_pred = rf.predict(x_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4d9873-7e48-442b-b676-3247868a4057",
   "metadata": {},
   "source": [
    "##### The accuracy seems to be extremly high. Lets check with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b4cad0d-6886-48ff-8272-51cde3f287ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9869942996291992\n",
      "Test Accuracy: 0.9883778847750291\n"
     ]
    }
   ],
   "source": [
    "# Check the accuracy on the training data and test data\n",
    "train_accuracy = rf.score(x_train, y_train)\n",
    "test_accuracy = rf.score(x_test, y_test)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365358e8-6411-49d1-8ba8-3d87010eea71",
   "metadata": {},
   "source": [
    "##### Given that both training and test accuracy is similar- it can suggest the model is generalizing well to the test data and isnt severly overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d529ee5-28d4-45bc-83b5-f13a908b8dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy: 0.9859 Â± 0.0019\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cv_scores = cross_val_score(rf, x_train, y_train, cv=5)\n",
    "print(f\"Cross-validation accuracy: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d0b9e7-f4e6-4e1c-b713-d513209a9cd6",
   "metadata": {},
   "source": [
    "##### cross validation results:\n",
    "\n",
    "The result of cross-validation accuracy indicates that the Random Forest model is consistently performing well across different data splits, and the performance is relatively stable (with a small standard deviation of 0.0014). This means that the model is not overfitting and should generalize well to unseen data.\n",
    "\n",
    "The deviation shows the model's performance is consistent across different data splits. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d3e932-d6ed-49f9-acc8-cd54ed927895",
   "metadata": {},
   "source": [
    "However, the accuracy is quite high (possibly due to the small datset we have). Lets fine tune the hyperparameters to see if it can prevent overfitting. \n",
    "\n",
    "We will find the ideal hyperparameters for the random forest model through random grid search. Given that grid search is computationally expensive and requires heavy processing, I have decide to use a random grid search, which will be quicker and require less processing power. The below range of values for our parameters hve been researched within the context of random forest models- we are using the average range. We are applying this to our validation data so that we can see the best combination of hyperparameters to unseen data. The model may memorise patterns seen in training data- before we even train the model- thus a seperate validation dataset needs to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521ba11a-8712-47c4-8142-ed40512d4cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Defining the hyperparameter grid here. we are using the validation set for this!\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "random_search_rf = RandomizedSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,\n",
    "    cv=10,\n",
    "    random_state=42,\n",
    "    n_jobs=4\n",
    ")\n",
    "\n",
    "# applying these parameters to our validation data and testing its performance:\n",
    "random_search_rf.fit(x_val, y_val)\n",
    "best_rf = random_search_rf.best_estimator_\n",
    "\n",
    "# Best parameters and accuracy\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best Model Accuracy:\", round(random_search.best_score_, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611f6966-a832-45b2-a0e1-1ba4d0780d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tuned_y_pred = best_rf.predict(x_test)\n",
    "y_pred_best_prob_rf = best_rf.predict_proba(x_test)[:, 1]\n",
    "print(\"Accuracy of the model: {}%\".format(accuracy(y_test, y_pred_best_rf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4501b269-fef2-4f0a-8bb2-86765c1642c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = cross_val_score(best_rf, x_val, y_val, cv=5)\n",
    "print(f\"Cross-validation accuracy: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c362d2-1f39-459f-86b5-ca9ddafb2b86",
   "metadata": {},
   "source": [
    "##### Interestingly, the accuracy of the hyperparameter tuned random forest model has worser accuracy. This may be from overfitting or too much complexity in the model. The slight drop from cross-validation accuracy (99.61%) to test accuracy (96.71%) is not uncommon and can happen due to factors like overfitting, data splitting, or variance in data difficulty.\n",
    "\n",
    "##### However, the standard deviation from cross validation is very small, indicating the model is stable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85aba3e-6b3a-40c2-acd7-470a4aab9d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_val, Tuned_y_pred) # creating confusion matrix against the validation data values and the predited ones in our new model\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "\n",
    "# Visualize confusion matrix with a heatmap\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='pink', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e353c0-006e-4ddc-ba81-8fc54e8b36e3",
   "metadata": {},
   "source": [
    "### Analysis of the confusion matrix:\n",
    "Here we have 11650 instances of the model correctly predicting the negative class (e.g., patients without diabetes), and 2 instances of correctly predicting the positive class. \n",
    "\n",
    "This shows that the model is struggling to predict the positve class (i.e., predicting diabetes) This may be a fault of the data- where in there is a high number of negatives versus true positives- thus the model may be heavily biased towards predicting the negative class. The high prediction thus may be towards predicting negatives alone. It seems we have highly imbalanced classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20b3dc2e-849a-41b8-b44e-b862c4492a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Below is graphical demonstration of just how unbalanced these classes are:\n",
    "\n",
    "sns.countplot(data= Final_df, x='Censor_Diabetes_Diagnosed')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f77d99-8142-4f50-8503-1773acfa3c2b",
   "metadata": {},
   "source": [
    "### Adapting the model: Lets use the random forest classifier to balance the weights and test this again. This will give more weight to the positive class e.g., the correct diagnosis of diabetes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1356df-d708-4ce0-92e0-2e35aaaf5a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Weighted_rf = RandomForestClassifier(class_weight='balanced', random_state=42, \n",
    "                                 n_estimators=best_rf.n_estimators, \n",
    "                                 max_depth=best_rf.max_depth, \n",
    "                                 min_samples_split=best_rf.min_samples_split)# using ideal hyperparameters + balancing the weight of the classes of diabetes\n",
    "\n",
    "\n",
    "Weighted_rf.fit(x_val, y_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b633a2b4-74c4-42e1-bd44-307939ae3743",
   "metadata": {},
   "outputs": [],
   "source": [
    "Weighted_y_pred = Weighted_rf.predict(x_test)\n",
    "best_rf = Weighted_rf.predict(x_test)\n",
    "print(\"Accuracy of the model: {}%\".format(accuracy(y_test, best_rf)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857b9836-87e9-45eb-b8c5-677c19acabcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_val, Weighted_y_pred) # creating confusion matrix against the validation data values and the predicted ones in our new model\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "\n",
    "# Visualize confusion matrix with a heatmap\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='pink', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5019bf49-bd9d-4127-b6eb-232f71da85d9",
   "metadata": {},
   "source": [
    "##### Perhaps the F1 score will highlight a better prediction. F1 score keeps the balance between precision and recall and improves the score only if the classifier identifies more of a certain class correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87706b09-3c0f-40ad-9fff-17e486097ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f1= f1_score(y_val, Weighted_y_pred)\n",
    "print(f\"f1 score is {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccf9ab9d-f48c-4170-a42a-242548f5317e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\yasmi\\pycharmprojects\\girr\\.venv\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in c:\\users\\yasmi\\pycharmprojects\\girr\\.venv\\lib\\site-packages (from imbalanced-learn) (2.0.2)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in c:\\users\\yasmi\\pycharmprojects\\girr\\.venv\\lib\\site-packages (from imbalanced-learn) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in c:\\users\\yasmi\\pycharmprojects\\girr\\.venv\\lib\\site-packages (from imbalanced-learn) (1.5.2)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in c:\\users\\yasmi\\pycharmprojects\\girr\\.venv\\lib\\site-packages (from imbalanced-learn) (0.1.3)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in c:\\users\\yasmi\\pycharmprojects\\girr\\.venv\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\yasmi\\pycharmprojects\\girr\\.venv\\lib\\site-packages (from imbalanced-learn) (3.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Users\\yasmi\\PycharmProjects\\Girr\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (C:\\Users\\yasmi\\PycharmProjects\\Girr\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Users\\yasmi\\PycharmProjects\\Girr\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (C:\\Users\\yasmi\\PycharmProjects\\Girr\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Users\\yasmi\\PycharmProjects\\Girr\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (C:\\Users\\yasmi\\PycharmProjects\\Girr\\.venv\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697a30d3-1530-4d73-86ee-1cbb8372b241",
   "metadata": {},
   "source": [
    "## This has not worked!\n",
    "\n",
    "Calculating an F1 score seems to be a better evaluator of performance of a binary classification model. Our f1 score is even worse- closer to 0 than 1 showing that this model is extremly poor at predicitng diabetes. Lets try a new technique, using a BalancedBaggingClassifier to see if this improves the model- we will use the 'best hyperparameters' from our grid search as beginning hyperparameters: Best Parameters: {'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_depth': 10, 'bootstrap': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7bb7c1-dcc7-4238-9f3c-7077b6a38951",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc = BalancedBaggingClassifier(\n",
    "    estimator= RandomForestClassifier(max_depth=10, min_samples_split=10),\n",
    "    random_state=42, \n",
    "    n_estimators= 100, \n",
    "    sampling_strategy = 'auto', # to balance the classes\n",
    "    replacement=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5b7d2b0-97bb-44ea-8d31-9def3e55a88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc.fit(x_train, y_train)\n",
    "\n",
    "y_predict=bbc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3c67d2e2-4313-4f59-897b-e6dfe0164d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      1.00      0.99     11831\n",
      "        True       0.97      0.36      0.52       215\n",
      "\n",
      "    accuracy                           0.99     12046\n",
      "   macro avg       0.98      0.68      0.76     12046\n",
      "weighted avg       0.99      0.99      0.99     12046\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29da632-1571-401d-997f-15d266da2bea",
   "metadata": {},
   "source": [
    "## Analysing the classification report \n",
    "Based on this classification report, the precision is high at 0.97 i.e., the model accurately predicts the individuals with diabetes (True in this binary data type). Out of all the non-diabetes patients, 99% predicted were correct.\n",
    "\n",
    "With recall however, the results differ. we get a result of 100% for correctly diagnosing the patient without diabetes. However, for diabetes, this is 36%. The F1 score is shockingly low at 0.52- which is less than ideal.  Random forest models may struggle with recall in highly imbalanced datasets such as this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ab9b7d-a367-4d09-9f88-d8a918e6cb49",
   "metadata": {},
   "source": [
    "# Lets try an SVM with class weighting. \n",
    "\n",
    "#### Why are we moving to an SVM model instead of our random forest one?\n",
    "\n",
    "After much research, it appears an SVM may work more effectively and use less memory resources than a random forest model, given its prowess with small datasets and imbalanced classes. SVM's have also commonly been applied to disease prediction models. The following reasons highlight how the SVM might outshine the random forest model in this case, despite their similarities:\n",
    "\n",
    "- SVMs can handle complex non-linear relationships- as stated previously, we are dealing with low correlations between diabetes diagnosis and the indicators- thus highlighting there is no clear linear relationship. Such is the norm with medical data and diagnoses.\n",
    "  \n",
    "- Our dataset is highly dimensional. There are roughly 20+ indicator features for diabetes diagnosis, all relevant for our usecase for the model.\n",
    "\n",
    "- Our medical data includes alot of outliers. SVMs are accustomed to focus on the support vectors and thus less susceptible to outlier influence.\n",
    "\n",
    "- finally, the small sample size we have would better suit an SVM.\n",
    "\n",
    "\n",
    "##### We will use class weights to balance out the data, giving much more weight to our diabetes positive diagnosis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ebd975d-20d3-4cf1-bc45-7feb9d6d1599",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "svm = SVC(kernel= 'linear', class_weight={0: 1, 1: 3}, probability=True, random_state=42)\n",
    "svm.fit(x_train, y_train)\n",
    "# note I am using a random kernel choice, based on research, linear seemed most fitting for class weights\n",
    "\n",
    "y_pred_svm = svm.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be5460dd-5c3f-4e8c-a04e-3f75c9c6218a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.99      1.00     11831\n",
      "        True       0.75      0.84      0.79       215\n",
      "\n",
      "    accuracy                           0.99     12046\n",
      "   macro avg       0.87      0.92      0.89     12046\n",
      "weighted avg       0.99      0.99      0.99     12046\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efaf1d6-9f27-4670-a123-ee60de8b121a",
   "metadata": {},
   "source": [
    "##### Here we have balanced the weights of each class using a common weight balance of 1:3, weighing the 'True' i.e., prediction of diabetes as higher. \n",
    "We are essentially making the model become more cautious about predicting positives, reducing false positives and making precision higher. \n",
    "\n",
    "Precision- weighted class balancing is useful in this scenario, where a false positive of diabetes diagnosis is highly undesired. We have a lot of negatives over positives on our data. Here the tradeoff between precision and recall is not awful. Lets hyperparameter tune with our validation dataset and see if we can improve these scores!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1b04c88-f842-4a1a-bbcc-fb637e4f000d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'kernel': 'linear', 'gamma': 0.001, 'degree': 5, 'coef0': 0, 'class_weight': {0: 1, 1: 3}, 'C': 1}\n"
     ]
    }
   ],
   "source": [
    "svm2 = SVC(probability=True, random_state=42)\n",
    "\n",
    "param_dist = {\n",
    "    'C': [0.1, 1, 10, 100],  \n",
    "    'kernel': ['rbf', 'linear'],  \n",
    "    'gamma': ['scale', 'auto', 0.001, 0.1],  \n",
    "    'class_weight': ['balanced', {0: 1, 1: 3}, {0: 1, 1: 5}],  # Class balancing options\n",
    "    'degree': [3, 4, 5],  \n",
    "    'coef0': [0, 0.1, 0.5] \n",
    "}\n",
    "random_search_CV = RandomizedSearchCV(\n",
    "    estimator=svm2,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,  # Number of random configurations to test\n",
    "    cv=5,  # Number of cross-validation folds\n",
    "    scoring='f1',  \n",
    "    n_jobs= 4,  \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "random_search_CV.fit(x_val, y_val)\n",
    "\n",
    "# Get the best parameters and the best model\n",
    "best_params = random_search_CV.best_params_\n",
    "best_model = random_search_CV.best_estimator_\n",
    "\n",
    "\n",
    "print(\"Best hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4dfd401-1f19-4f7f-9caf-78168a84fead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions on the test set\n",
    "y_pred_svm2 = best_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1776d4e8-eb3e-4467-8940-60fefeccabd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00     11831\n",
      "        True       0.83      0.80      0.81       215\n",
      "\n",
      "    accuracy                           0.99     12046\n",
      "   macro avg       0.91      0.90      0.90     12046\n",
      "weighted avg       0.99      0.99      0.99     12046\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svm2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffeed440-d825-4be3-abce-33103d40bc5c",
   "metadata": {},
   "source": [
    "##### What we see here is a greatly improved model. \n",
    "The F1 score has increased greatly to 0.81, highlighting a great tradeoff and maximisation of both precision and recall. We focused on the f1 score here as it is a much more comprehensive evaluation metric. This is a large step up from our random forest model, using balanced weights were we saw the F1 score as 0.52. It is important that this score is as high as possible, as we want to ensure correct diagnosis between the 2 result classes as accurately as possible. \n",
    "\n",
    "Whilst the recall value for true diagnosis of diabetes has dropped from 0.84-0.80 after hyperparameters being tuned, the precision has increased. This is key for our model, as precision will measure how often it correctly predicted the positive instance of diabetes- whch is the main aim of the model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552f9306-c241-4cb8-8088-126180d3149d",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391ec6df-8943-4a88-bb0d-647fc4f363d3",
   "metadata": {},
   "source": [
    "Our final model best fitting to this dataset and use case is our SVM 'best_model'. This was a weight balanced model, with a final F1-score of 0.81 for the correct diagnosis of diabetes, and 1.00 for the negative case. This greatly outshined our random forest model- which we experimented on twice with tuning hyperparameters, and using balanced weights for the classes. \n",
    "\n",
    "Whilst we could have fitted a weighted class identifier to the random forest model, it was important for the assignment context to explore other model types and see their ability to correctly diagnose. \n",
    "\n",
    "### Limitations\n",
    "It is important to note the limitations of our random search parameters. Given the lengthy time it takes for the function to run and the low processing power of the local computer, fewer parameters and 'n_jobs' was set to 4 for the CPU core. This seemed to work best given the time taken to random search for the model. Ideally, more random configurations would be used, and perhaps a grid search, looking at all combinations would more accurately define the best hyperparameters. \n",
    "\n",
    "### Application of the model on real data?\n",
    "\n",
    "Due to the nature of the model, and how complex diagnosis detection is, I do not believe this model is fit for application in a hospital setting as it is right now. However, with more data following the same context of this data (e.g., wide age range, wide range of values etc) and more testing by experts, I believe a model such as this could be placed within the healthcare environment. For example, since majority of features are indeed blood test values, patient data could be extracted from a simple blood test, and questinnaire on their BMI, smoking/drinking status and family history, then fed into the model to determine their diagnosis of type 2 diabetes, saving time within the NHS for analysis of results, whilst also providing a quicker answer to the patient. Diabetes type 2 is manageable and even reversible, so speed of diagnosis is crucial for this application."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
